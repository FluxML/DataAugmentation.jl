[{"doctype":"documentation","id":"references/DataAugmentation.ToEltype","title":"ToEltype","text":"tfm Float32 item rand Int tfm item Converts any  AbstractArrayItem  to an  AbstractArrayItem{N T  Supports  apply  Examples"},{"doctype":"document","id":"documents/CHANGELOG.md","title":"Changelog","text":"Changelog All notable changes to this project will be documented in this file The format is based on  Keep a Changelog  and this project adheres to  Semantic Versioning  Unreleased 0.2.6 Fixed CenterCrop  and co now work properly on their own fixes  52  0.2.5 Added TableRow  item transforms for  TableRow   FillMissing   Categorify  and  NormalizeRow 0.2.4 Changed Buffered  now stores a  Dict  of item type  buffer to alleviate the need to recreate buffers if the buffered transform is applied to multiple items 0.2.3 Changed BufferedThreadsafe  now properly passes through explicit random state ScaleKeepAspect  no longer sometimes produces a black border fix   Sequence  Sequence  now has a method ToTensor  now works on different color types and N-dimensional arrays MaskMulti  now has a constructor for  IndirectArray s 0.1.5  2021-04-17 Added Color augmentation transforms Stochastic transformation wrappers WarpAffine  projective transformation Changed Moved documentation generation to  Pollen.jl"},{"doctype":"documentation","id":"references/DataAugmentation.ScaleRatio","title":"ScaleRatio","text":""},{"doctype":"documentation","id":"references/DataAugmentation.showitem!","title":"showitem!","text":"Visualize  item  Should return an image"},{"doctype":"documentation","id":"references/DataAugmentation.Polygon","title":"Polygon","text":"StaticArrays points SVector SVector SVector SVector item points item Item wrapper around  Keypoints  Examples"},{"doctype":"documentation","id":"references/DataAugmentation.ResizePadDivisible","title":"ResizePadDivisible","text":""},{"doctype":"documentation","id":"references/DataAugmentation.Maybe","title":"Maybe","text":"With probability  p  apply transformation  tfm "},{"doctype":"documentation","id":"references/DataAugmentation.centered","title":"centered","text":"Transform  P  so that is applied around the center of  bounds  instead of the origin"},{"doctype":"documentation","id":"references/DataAugmentation.MaskBinary","title":"MaskBinary","text":"mask rand Bool mask An  N dimensional binary mask Examples"},{"doctype":"documentation","id":"references/DataAugmentation.threepointwarpaffine","title":"threepointwarpaffine","text":"Calculate an affine  CoordinateTransformations.LinearMap  from 3 source points to 3 destination points Adapted from   CoordinateTransformations.jl#30 "},{"doctype":"documentation","id":"references/DataAugmentation.getprojection","title":"getprojection","text":"Create a projection for an item with spatial bounds  bounds  The projection should be a  CoordinateTransformations.Transformation  See  CoordinateTransformations.jl"},{"doctype":"documentation","id":"references/DataAugmentation.Normalize","title":"Normalize","text":"Images image rand RGB tfms tfms image Normalizes the last dimension of an  AbstractArrayItem{N  Supports  apply  Examples Preprocessing a 3D image with 3 color channels"},{"doctype":"document","id":"documents/docs/literate/projective/gallery.md","title":"Gallery","text":"MosaicViews Images TestImages StaticArrays imagedata testimage imagedata imresize imagedata ratio size imagedata imagedata testimage imagedata tfm image imagedata tfm image points SVector Float32 SVector SVector bbox points size imagedata image bbox tfm tfm image tfm bbox tfm image bbox showtransform tfm item n ncol mosaicview tfm item _ n fillvalue RGBA npad rowmajor ncol ncol showtransforms tfms item ncol length tfms mosaicview parent tfm item tfm tfms fillvalue RGBA npad rowmajor ncol ncol tfm o showtransform tfm image bbox ncol tfm o showtransform tfm image bbox tfms o showtransforms tfms image bbox tfms o showtransforms tfms image bbox tfm o showtransform tfm image bbox Gallery Let's visualize what these projective transformations look like You can apply them to  Image s and the keypoint-based items  Keypoints   Polygon  and  BoundingBox  Let's take this picture of a light house To apply a transformation  tfm  to it wrap it in  Image  apply the transformation and unwrap it using  itemdata  Now let's say we want to train a light house detector and have a bounding box for the light house We can use the  BoundingBox  item to represent it It takes the two corners of the bounding rectangle as the first argument As the second argument we have to pass the size of the corresponding image showitems  visualizes the two items If we apply transformations like translation and cropping to the image then the same transformations have to be applied to the bounding box Otherwise the bounding box will no longer match up with the light house Another problem can occur with stochastic transformations like  RandomResizeCrop  If we apply it separately to the image and the bounding box they will be cropped from slightly different locations Instead pass a tuple of the items to a single  apply  call so the same random state will be used for both image and bounding box 3D Projective dimensions We'll use a 2-dimensional  Image  and  BoundingBox  here but you can apply most projective transformations to any spatial item including  Keypoints   MaskBinary  and  MaskMulti  in 3 dimensions Of course you have to create a 3-dimensional transformation i.e  CenterCrop((128 128 128  instead of  CenterCrop((128 128  Gallery RandomResizeCrop sz Resizes the sides so that one of them is no longer than  sz  and crops a region of size  sz   from a random location  CenterResizeCrop Resizes the sides so that one of them is no longer than  sz  and crops a region of size  sz   from the center  Crop sz from Crops a region of size  sz  from the image  without resizing  the image first FlipX   FlipY   Reflect Flip the data on the horizontally and vertically respectively More generally reflect around an angle from the x-axis Rotate Rotate counter-clockwise by an angle"},{"doctype":"documentation","id":"references/DataAugmentation.adjustcontrast!","title":"adjustcontrast!","text":""},{"doctype":"document","id":"documents/docs/literate/tfminterface.md","title":"Transformation interface","text":"f tfm item randstate nothing a item a_ map tfm f a item a_ bufitem I tfm item I randstate nothing I map! tfm f bufitem item bufitem tfm1 tfm2 MapElem2 tfm2 f tfm1 f Transformation interface base.jl The transformation interface is the centrepiece of this library Beside straightforward transform application it also enables stochasticity composition and buffering A transformation is a type that subtypes  Transform  The only  required  function to implement for your transformation type  T  is apply tfm::T item::I randstate Applies the transformation  tfm  to item  item  Implemented methods can of course dispatch on the type of  item   randstate  encapsulates the random state needed for stochastic transformations The  apply  method implementation itself should be deterministic You may dispatch on a specific item type  I  or use the abstract  Item  if one implementation works for all item types You may additionally also implement getrandstate tfm  for  stochastic  transformations Generates random state to be used inside  apply  Calling  apply(tfm item  is equivalent to  apply(tfm item randstate  getrandstate(tfm  It defaults to  nothing  so we need not implement it for deterministic transformations apply bufitem tfm::T item randstate  to support  buffering Buffered version of  apply  that mutates  bufitem  If not implemented falls back to regular  apply  compose tfm1 tfm2  for custom  composition  with other transformations Composes transformations By default returns a  Sequence  transformation that applies the transformations one after the other Example The implementation of the  MapElem  transformation illustrates this interface well It transforms any item with array data by mapping a function over the array's elements just like  Base.map  The  apply  implementation dispatches on  AbstractArrayItem  an abstract item type for items that wrap arrays Note that the  randstate  keyword argument needs to be given even for implementations of deterministic transformations We also make use of the  setdata  helper to update the item data The buffered version applies the function inplace using  Base.map  Finally a  MapElem  can also be composed nicely with other  MapElem s Instead of applying them sequentially the functions are fused and applied once"},{"doctype":"documentation","id":"references/DataAugmentation.tensortoimage","title":"tensortoimage","text":""},{"doctype":"documentation","id":"references/DataAugmentation.ComposedProjectiveTransform","title":"ComposedProjectiveTransform","text":"Wrap multiple projective  tfms  and apply them efficiently The projections are fused into a single projection and only points inside the final crop are evaluated"},{"doctype":"documentation","id":"references/DataAugmentation.AbstractCrop","title":"AbstractCrop","text":""},{"doctype":"documentation","id":"references/DataAugmentation.testapply","title":"testapply","text":"Test  apply  invariants of  tfm  on  item  or item type  I  With a constant  randstate  parameter  apply  should always return the same result"},{"doctype":"documentation","id":"references/DataAugmentation.MaskMulti","title":"MaskMulti","text":"mask rand mask An  N dimensional multilabel mask with labels  classes  Examples"},{"doctype":"documentation","id":"references/DataAugmentation.showitems","title":"showitems","text":"Visualize  items "},{"doctype":"documentation","id":"references/DataAugmentation.Crop","title":"Crop","text":""},{"doctype":"documentation","id":"references/DataAugmentation.corners","title":"corners","text":""},{"doctype":"document","id":"documents/docs/literate/intro.md","title":"DataAugmentation.jl","text":"item image tfm tfm item DataAugmentation.jl This library provides data transformations for machine and deep learning At the moment it focuses on spatial data think images keypoint data and masks but that is owed only to my current work The extensible abstractions should fit other domains as well For the most part the transformations themselves are not very complex The challenge this library tackles is to reconcile an easy-to-use composable interface with performant execution The key abstractions are  Transform s the transformation to apply and  Item s which contain the data to be transformed  apply tfm item  as the name gives away applies a transformation to an item  For example given an  Image  item we can resize it with the  CenterResizeCrop  transformation Requirements The above example is simple but there are more requirements of data augmentation pipelines that this library adresses They serve as a motivation to the interface I've arrived at for defining transformations Stochasticity A transformation is stochastic as opposed to deterministic if it produces different outputs based on some random state This randomness can become a problem when applying an transformation to an aligned pair of input and target If we have an image and a corresponding segmentation mask using different scaling factors results in misalignment of the two the segmentation no longer matches up with the image pixels To handle this the random state is explicitly passed to the transformations rendering them deterministic A generator for the random state can be defined with  getrandstate tfm  and passed to  apply  with the  randstate  keyword argument Composition Most data augmentation pipelines are made up of multiple steps augmenting an image can mean resizing randomly rotating cropping and then normalizing the values So applying transformations one after another – sequencing – is one way to compose transformations But some operations like affine transformations can also be  fused  resulting in a single transformation that is more performant and produces more accurate results Buffering Since data augmentation pipelines often run on large amounts of data performance can often be improved by using prealloacted output buffers for the transformations This results in fewer memory allocations and less garbage collection which both take time Let's next see how these requirements are reflected in the  item  and  transformation  interfaces"},{"doctype":"documentation","id":"references/DataAugmentation.showbounds!","title":"showbounds!","text":""},{"doctype":"document","id":"documents/docs/literate/quickstart.md","title":"Quickstart","text":"TestImages ImageShow Images TestImages testimage image testimage image imresize testimage ratio item image tfm titem tfm item timage titem Quickstart Import the library Load your data Create an item that contains the data you want to augment Create a transform Apply the transformation and unwrap the data"},{"doctype":"documentation","id":"references/DataAugmentation.FromOrigin","title":"FromOrigin","text":""},{"doctype":"documentation","id":"references/DataAugmentation.denormalize","title":"denormalize","text":""},{"doctype":"documentation","id":"references/DataAugmentation.copyitemdata!","title":"copyitemdata!","text":""},{"doctype":"documentation","id":"references/DataAugmentation.Image","title":"Image","text":"Images imagedata rand RGB item imagedata item imagedata rand Float32 item imagedata item Item representing an N-dimensional image with element type T Examples If  T  is not a color the image will be interpreted as grayscale"},{"doctype":"documentation","id":"references/DataAugmentation.setwrapped","title":"setwrapped","text":""},{"doctype":"documentation","id":"references/DataAugmentation.Identity","title":"Identity","text":"The identity transformation"},{"doctype":"documentation","id":"references/DataAugmentation.FlipX","title":"FlipX","text":""},{"doctype":"documentation","id":"references/DataAugmentation.compose","title":"compose","text":"Compose tranformations Use    as an alias Defaults to creating a  Sequence  of transformations but smarter behavior can be implemented For example  MapElem(f  MapElem(g  MapElem(g ∘ f "},{"doctype":"documentation","id":"references/DataAugmentation.offsetcropbounds","title":"offsetcropbounds","text":"Calculate offset bounds for a crop of size  sz  For every dimension i where  sz[i  length(indices[i  offsets the crop by  offsets[i  times the difference between the two"},{"doctype":"documentation","id":"references/DataAugmentation.showkeypoint!","title":"showkeypoint!","text":""},{"doctype":"documentation","id":"references/DataAugmentation.PinOrigin","title":"PinOrigin","text":"Projective transformation that translates the data so that the upper left bounding corner is at the origin  0 0  or the multidimensional equivalent Projective transformations on images return  OffsetArray s but not on keypoints Hardware like GPUs do not support OffsetArrays so they will be unwrapped and no longer match up with the keypoints Pinning the data to the origin makes sure that the resulting  OffsetArray  has the same indices as a regular array starting at one"},{"doctype":"documentation","id":"references/DataAugmentation.denormalize!","title":"denormalize!","text":""},{"doctype":"documentation","id":"references/DataAugmentation.setdata","title":"setdata","text":""},{"doctype":"documentation","id":"references/DataAugmentation.CroppedProjectiveTransform","title":"CroppedProjectiveTransform","text":""},{"doctype":"document","id":"documents/docs/literate/projective/data.md","title":"Spatial data","text":"Spatial data Before introducing various projective transformations we have a look at the data that can be projected There are three kinds of data currently supported images keypoints and segmentation masks Both 2D and 3D data is supported and technically higher dimensions but I've yet to find a dataset with 4 spatial dimensions Image N T  represents an  N dimensional image  T  refers to the element type of the array that  Image  wraps usually a color When projecting images proper interpolation methods are used to reduce artifacts like aliasing See  image.jl MaskBinary N  and  MaskMulti N T  likewise represents  N dimensional segmentation masks Unlike images nearest-neighbor interpolation is used for projecting masks See  mask.jl Lastly  Keypoints N  represent keypoint data The data should be an array of  SVector{N  Since there are many interpretations of keypoint data there are also wrapper items for convenience  BoundingBox  and  Polygon See  keypoints.jl"},{"doctype":"documentation","id":"references/DataAugmentation.showpolygon!","title":"showpolygon!","text":""},{"doctype":"documentation","id":"references/DataAugmentation.Sequence","title":"Sequence","text":"Transform  that applies multiple  transformations  after each other You should not use this explicitly Instead use  compose "},{"doctype":"documentation","id":"references/DataAugmentation.Buffered","title":"Buffered","text":""},{"doctype":"document","id":"documents/docs/literate/projective/usage.md","title":"Usage","text":"Usage Using projective transformations is as simple as any other transformations Simply  compose  them The composition will automatically create a single projective transformation and evaluate only the cropped area Affine transformations Affine transformations are a subgroup of projective transformations that can be composed very efficiently composing two affine transformations results in another affine transformation Affine transformations can represent translation scaling reflection and rotation Available  Transform s are ScaleRatio   ScaleKeepAspect Rotate FlipX   FlipY   Reflect WarpAffine Crops To get a cropped result simply  compose  any  ProjectiveTransform  with CenterCrop  to crop a fixed-size region from the center or RandomCrop  to crop a fixed-size region from a random position"},{"doctype":"documentation","id":"references/DataAugmentation.apply!","title":"apply!","text":"Applies  tfm  to  item  mutating the preallocated  buffer  buffer  can be obtained with  buffer  makebuffer(tfm item Default to  apply(tfm item  non-mutating version"},{"doctype":"documentation","id":"references/DataAugmentation.Categorify","title":"Categorify","text":"cols col1 col2 col3 row zip cols item row cols catdict Dict col1 tfm catdict col1 tfm item Label encodes the values of a row present in  TabularItem  for the columns specified in  cols  using  dict  which contains the column names as dictionary keys and the unique values of column present as dictionary values if there are any  missing  values in the values to be transformed they are replaced by 1 Example"},{"doctype":"document","id":"documents/docs/literate/iteminterface.md","title":"Item interface","text":"MyItem data Item interface As described previously items are simply containers for data an  Image  represents an image and  Keypoints  some keypoints Why do I need to wrap my data in an item For one the item  struct s may contain metadata that is useful for some transformations More importantly though by wrapping data in an item type the  meaning  of the data is separated from the  representation  that is the concrete type An  Array{Integer 2  could represent an image but also a multi-class segmentation mask Is  Array{Float32 3  a 3-dimensional image or a 2-dimensional image with the color channels expanded Separating the representation from the data's meaning resolves those ambiguities Creating items To create a new item you can simply subtype  Item  The only function that is expected to be implemented is  itemdata  which simply returns the wrapped data If as above you simply call the field holding the data  data  you do not need to implement it The same goes for the  setdata  helper For some items it also makes sense to implement the following showitem img item::I  creates a visual representation of an item on top of  img "},{"doctype":"documentation","id":"references/DataAugmentation.OneOf","title":"OneOf","text":"Apply one of  tfms  selected randomly with probability  ps  each or uniformly chosen if no  ps  is given"},{"doctype":"documentation","id":"references/DataAugmentation.CropFrom","title":"CropFrom","text":""},{"doctype":"documentation","id":"references/DataAugmentation.testapply!","title":"testapply!","text":"Test  apply  invariants With a constant  randstate  parameter  apply  should always return the same result Given a different item than was used to create the buffer the buffer's data should be modified"},{"doctype":"documentation","id":"references/DataAugmentation.PadDivisible","title":"PadDivisible","text":""},{"doctype":"documentation","id":"references/DataAugmentation.RandomCrop","title":"RandomCrop","text":""},{"doctype":"documentation","id":"references/DataAugmentation.itemfield","title":"itemfield","text":""},{"doctype":"documentation","id":"references/DataAugmentation.getrandstate","title":"getrandstate","text":"Generates random state for stochastic transformations Calling  apply(tfm item  is equivalent to  apply(tfm item randstate  getrandstate(tfm  It defaults to  nothing  so you it only needs to be implemented for stochastic  Transform s"},{"doctype":"documentation","id":"references/DataAugmentation.testitem","title":"testitem","text":"Create an instance of an item with type  TItem  If it has spatial bounds should return an instance with bounds with ranges 1:16 1:16"},{"doctype":"documentation","id":"references/DataAugmentation.TabularItem","title":"TabularItem","text":""},{"doctype":"documentation","id":"references/DataAugmentation.fmap","title":"fmap","text":""},{"doctype":"documentation","id":"references/DataAugmentation.scaleprojection","title":"scaleprojection","text":""},{"doctype":"documentation","id":"references/DataAugmentation.showgrid","title":"showgrid","text":""},{"doctype":"document","id":"documents/README.md","title":"DataAugmentation.jl","text":"DataAugmentation.jl Documentation  Latest Efficient composable data augmentation for machine and deep learning with support for n-dimensional images keypoints and categorical masks"},{"doctype":"documentation","id":"references/DataAugmentation.Rotate","title":"Rotate","text":"tfm Rotate 2D spatial data around the center by an angle chosen at uniformly from γ γ an angle given in degrees You can also pass any  Distributions.Sampleable  from which the angle is selected Examples"},{"doctype":"documentation","id":"references/DataAugmentation.project","title":"project","text":"Project  item  using projection  P  and crop to  indices  if given"},{"doctype":"documentation","id":"references/DataAugmentation.imagetotensor","title":"imagetotensor","text":""},{"doctype":"document","id":"documents/docs/literate/buffering.md","title":"Buffering","text":"buffer tfm item buffer tfm item buffered tfm buffer tfm item Buffering As mentioned in the section on  transformations  you can implement  apply  as an inplace version of  apply  to support buffered transformations Usually the result of a regular  apply  can be used as a buffer You may write However for some transformations a different buffer is needed  Sequence  for example needs to reuse all intermediate results That is why the buffer creation can be customized makebuffer tfm item  creates a buffer  buf  that can be used in an  apply  call  apply!(buf tfm item  Managing the buffers manually quickly becomes tedious For convenience this library implements  Buffered  a transformation wrapper that will use a buffer internally  btfm  Buffered(tfm  will create a buffer the first time it is  apply ed and then use it by internally calling  apply  Since  Buffered  only stores one buffer you may run into problems when using it in a multi-threading context where different threads invalidate the buffer before it can be used In that case you can use  BufferedThreadsafe  a version of  Buffered  that keeps a separate buffer for every thread"},{"doctype":"document","id":"documents/docs/literate/stochastic.md","title":"Stochastic transformations","text":"TestImages item testimage tfm titems tfm item _ titems ncol npad Stochastic transformations When augmenting data it is often useful to apply a transformation only with some probability or choose from a set of transformations Unlike in other data augmentation libraries like  albumentations  in DataAugmentation.jl you can use wrapper transformations for this functionality Maybe tfm p  0.5  applies a transformation with probability  p  and OneOf tfm1 tfm2  randomly selects a transformation to apply Example Let's say we have an image classification dataset For most datasets horizontally flipping the image does not change the label a flipped image of a cat still shows a cat So let's flip every image horizontally half of the time to improve the generalization of the model we might be training"},{"doctype":"documentation","id":"references/DataAugmentation.RandomResizeCrop","title":"RandomResizeCrop","text":""},{"doctype":"documentation","id":"references/DataAugmentation.AdjustContrast","title":"AdjustContrast","text":"TestImages item testimage tfm titems tfm item _ titems ncol npad Adjust the contrast of an image by a factor chosen uniformly from  f ∈ 1-δ 1+δ  Pixels  c  are transformed  c  μ*(1-f  where  μ  is the mean color of the image You can also pass any  Distributions.Sampleable  from which the factor is selected Example"},{"doctype":"documentation","id":"references/DataAugmentation.getbounds","title":"getbounds","text":"Return the spatial bounds of  item  For a 2D-image  Image{2  the bounds are the 4 corners of the bounding rectangle In general for an N-dimensional item the bounds are a vector of the N^2 corners of the N-dimensional hypercube bounding the data"},{"doctype":"documentation","id":"references/DataAugmentation.Project","title":"Project","text":""},{"doctype":"documentation","id":"references/DataAugmentation.OneOfProjective","title":"OneOfProjective","text":""},{"doctype":"documentation","id":"references/DataAugmentation.showbounds","title":"showbounds","text":""},{"doctype":"documentation","id":"references/DataAugmentation.Keypoints","title":"Keypoints","text":"StaticArrays points SVector y x y x zip item points item N dimensional keypoints represented as  SVector{N T  Spatial bounds are given by the polygon  bounds::Vector{SVector{N T  or  sz::NTuple{N Int  Examples"},{"doctype":"documentation","id":"references/DataAugmentation.BufferedThreadsafe","title":"BufferedThreadsafe","text":""},{"doctype":"documentation","id":"references/DataAugmentation.NormalizeRow","title":"NormalizeRow","text":"cols col1 col2 col3 row zip cols item row cols normdict Dict col1 col2 tfm normdict col1 col2 tfm item Normalizes the values of a row present in  TabularItem  for the columns specified in  cols  using  dict  which contains the column names as dictionary keys and the mean and standard deviation tuple present as dictionary values Example"},{"doctype":"documentation","id":"references/DataAugmentation.project!","title":"project!","text":"Project  item  using projection  P  and crop to  indices  if given Store result in  bufitem  Inplace version of  project  Default implementation falls back to  project "},{"doctype":"documentation","id":"references/DataAugmentation.Transform","title":"Transform","text":"Abstract supertype for all transformations"},{"doctype":"documentation","id":"references/DataAugmentation.adjustcontrast","title":"adjustcontrast","text":""},{"doctype":"documentation","id":"references/DataAugmentation.ImageToTensor","title":"ImageToTensor","text":"Images image rand RGB tfm tfm image Expands an  Image{N T  of size  sz  to an  ArrayItem{N+1  with size  sz ch  where  ch  is the number of color channels of  T  Supports  apply  Examples"},{"doctype":"documentation","id":"references/DataAugmentation.AdjustBrightness","title":"AdjustBrightness","text":"TestImages item testimage tfm titems tfm item _ titems ncol npad Adjust the brightness of an image by a factor chosen uniformly from  f ∈ 1-δ 1+δ  by multiplying each color channel by  f  You can also pass any  Distributions.Sampleable  from which the factor is selected Example"},{"doctype":"documentation","id":"references/DataAugmentation.BoundingBox","title":"BoundingBox","text":"StaticArrays points SVector SVector item points item Item wrapper around  Keypoints  Examples"},{"doctype":"documentation","id":"references/DataAugmentation.Reflect","title":"Reflect","text":"tfm Reflect 2D spatial data around the center by an angle chosen at uniformly from γ γ an angle given in degrees You can also pass any  Distributions.Sampleable  from which the angle is selected Examples"},{"doctype":"documentation","id":"references/DataAugmentation.projectionbounds","title":"projectionbounds","text":""},{"doctype":"documentation","id":"references/DataAugmentation.ItemWrapper","title":"ItemWrapper","text":""},{"doctype":"documentation","id":"references/DataAugmentation.AbstractItem","title":"AbstractItem","text":"Abstract supertype for all items To implement items subtype either  Item  to create a new item or  ItemWrapper  to wrap an existing item"},{"doctype":"documentation","id":"references/DataAugmentation.imagetotensor!","title":"imagetotensor!","text":""},{"doctype":"documentation","id":"references/DataAugmentation.CenterResizeCrop","title":"CenterResizeCrop","text":""},{"doctype":"documentation","id":"references/DataAugmentation.AbstractArrayItem","title":"AbstractArrayItem","text":"Abstract type for all  Item s that wrap an  N dimensional array with element type  T "},{"doctype":"documentation","id":"references/DataAugmentation.NormalizeIntensity","title":"NormalizeIntensity","text":""},{"doctype":"documentation","id":"references/DataAugmentation.FromRandom","title":"FromRandom","text":""},{"doctype":"documentation","id":"references/DataAugmentation.normalize!","title":"normalize!","text":""},{"doctype":"documentation","id":"references/DataAugmentation.showimage!","title":"showimage!","text":""},{"doctype":"documentation","id":"references/DataAugmentation.apply","title":"apply","text":"Apply  tfm  to an  item  or a tuple  items "},{"doctype":"documentation","id":"references/DataAugmentation.OneHot","title":"OneHot","text":"item rand item One-hot encodes a  MaskMulti  with  n  classes and size  sz  into an array item of size  sz n  with element type  T  Supports  apply "},{"doctype":"documentation","id":"references/DataAugmentation.getwrapped","title":"getwrapped","text":""},{"doctype":"documentation","id":"references/DataAugmentation.adjustbrightness!","title":"adjustbrightness!","text":""},{"doctype":"document","id":"documents/docs/literate/projective/interface.md","title":"interface","text":"Projective transformations interface The abstract type  ProjectiveTransform  represents a projective transformation A  ProjectiveTransform  needs to implement  getprojection tfm bounds randstate  that should return a  Transformation  from  CoordinateTransformations.jl  To add support for projective transformations to an item  I  you need to implement getbounds(item::I  returns the spatial bounds of the item and project(P item::I indices  applies the projective transformation  P  and crops to  indices To support  apply ing projective transformations  project!(bufitem P item  can also be implemented"},{"doctype":"documentation","id":"references/DataAugmentation.ArrayItem","title":"ArrayItem","text":"An item that contains an array"},{"doctype":"documentation","id":"references/DataAugmentation.Item","title":"Item","text":"Abstract supertype of concrete items Subtype if you want to create a new item If you want to wrap an existing item see  ItemWrapper "},{"doctype":"documentation","id":"references/DataAugmentation.boundsof","title":"boundsof","text":"Find bounding index ranges for points  ps "},{"doctype":"documentation","id":"references/DataAugmentation.FromCenter","title":"FromCenter","text":""},{"doctype":"documentation","id":"references/DataAugmentation.CenterCrop","title":"CenterCrop","text":""},{"doctype":"documentation","id":"references/DataAugmentation.reflectionmatrix","title":"reflectionmatrix","text":""},{"doctype":"documentation","id":"references/DataAugmentation","title":"DataAugmentation","text":""},{"doctype":"documentation","id":"references/DataAugmentation.Bounds","title":"Bounds","text":""},{"doctype":"documentation","id":"references/DataAugmentation.WarpAffine","title":"WarpAffine","text":"A three-point affine warp calculated by randomly moving 3 corners of an item Similar to a random translation shear and rotation"},{"doctype":"documentation","id":"references/DataAugmentation.onehot","title":"onehot","text":""},{"doctype":"document","id":"documents/docs/literate/preprocessing.md","title":"Preprocessing","text":"Preprocessing This library also implements some general transformations useful for getting data ready to be put into a model ToEltype T  converts the element type of any  AbstractArrayItem  to  T  ImageToTensor  converts an image to an  ArrayItem  with another dimension for the color channels Normalize  normalizes image tensors OneHot  to one-hot encode multi-class masks  MaskMulti s"},{"doctype":"documentation","id":"references/DataAugmentation.mask_extrapolation","title":"mask_extrapolation","text":""},{"doctype":"documentation","id":"references/DataAugmentation.ScaleKeepAspect","title":"ScaleKeepAspect","text":"TestImages image testimage tfm tfm image Scales the shortest side of  item  to  minlengths  keeping the original aspect ratio Examples"},{"doctype":"documentation","id":"references/DataAugmentation.itemdata","title":"itemdata","text":"Access the data wrapped in  item  or a tuple of items"},{"doctype":"document","id":"documents/docs/literate/colortransforms.md","title":"Color transformations","text":"Color transformations DataAugmentation.jl currently supports the following color transformations for augmentation AdjustContrast  randomly adjusts the contrast and AdjustBrightness  randomly adjusts the brightness See the docstrings for examples"},{"doctype":"documentation","id":"references/DataAugmentation.testprojective","title":"testprojective","text":"Test invariants of a  ProjectiveTransform  getprojection  is defined and given a constant  randstate  parameter always returns the same result It preserves the item type i.e  apply(tfm I  I  Applying it to multiple items with the same bounds results in the same bounds for all items"},{"doctype":"documentation","id":"references/DataAugmentation.ScaleFixed","title":"ScaleFixed","text":"Projective transformation that scales sides to  sizes  disregarding aspect ratio See also  ScaleKeepAspect "},{"doctype":"documentation","id":"references/DataAugmentation.ProjectiveTransform","title":"ProjectiveTransform","text":"Abstract supertype for projective transformations See  Projective transformations "},{"doctype":"documentation","id":"references/DataAugmentation.transformbounds","title":"transformbounds","text":"Apply  CoordinateTransformations.Transformation  to  bounds "},{"doctype":"documentation","id":"references/DataAugmentation.makebuffer","title":"makebuffer","text":"Create a buffer  buf  that can be used in a call to  apply!(buf tfm item  Default to  buffer  apply(tfm item  You only need to implement this if the default  apply(tfm item  isn't enough See  apply(tfm::Sequence item  for an example of this"},{"doctype":"documentation","id":"references/DataAugmentation.normalize","title":"normalize","text":""},{"doctype":"documentation","id":"references/DataAugmentation.FlipY","title":"FlipY","text":""},{"doctype":"documentation","id":"references/DataAugmentation.Zoom","title":"Zoom","text":"Zoom into an item by a factor chosen from the interval  scales  or  distribution "},{"doctype":"documentation","id":"references/DataAugmentation.FillMissing","title":"FillMissing","text":"cols col1 col2 col3 row zip cols item row cols fmdict Dict col1 col2 tfm fmdict col1 col2 tfm item Fills the missing values of a row present in  TabularItem  for the columns specified in  cols  using  dict  which contains the column names as dictionary keys and the value to fill the column with present as dictionary values Example"},{"doctype":"documentation","id":"references/DataAugmentation.adjustbrightness","title":"adjustbrightness","text":""},{"doctype":"document","id":"documents/docs/literate/projective/intro.md","title":"Projective transformations","text":"h w Projective transformations DataAugmentation.jl has great support for transforming spatial data like images and keypoints Most of these transformations are projective transformations For our purposes a projection means a mapping between two coordinate spaces In computer vision these are frequently used for preprocessing and augmenting image data images are randomly scaled maybe flipped horizontally and finally cropped to the same size This library generalizes projective transformations for different kinds of image and keypoint data in an N-dimensional Euclidean space It also uses composition for performance improvements like fusing affine transformations Unlike mathematical objects the spatial data we want to transform has  spatial bounds  For an image these bounds are akin to the array size But keypoint data aligned with an image has the same bounds even if they are not explicitly encoded in the representation of the data These spatial bounds can be used to dynamically create useful transformations For example a rotation around the center or a horizontal flip of keypoint annotations can be calculated from the bounds Often we also want to  crop  an area from the projected results By evaluating only the parts of a projection that fall inside the cropped area a lot of unnecessary computation can be avoided An example pipeline We can break down most augmentation used in practive into a single possibly stochastic projection and a crop As an example consider an image augmentation pipeline A random horizontal flip followed by a random resized crop The latter resizes and crops irregularly sized images to a common size without distorting the aspect ratio Let's pull apart the steps involved Half of the time flip the image horizontally Scale the image down without distortion so that the shorter side length is 128 With an input of size  512 256  this result in scaling both dimensions by  1/2  resulting in an image with side lengths  256 128  Crop a random  128 128  portion from that image There is only wiggle room on the y-axis which by convention is the first All of these steps can be efficiently computed in one step with two tricks Some projections like reflection translation scaling and rotation can be composed into a single projection matrix This means in the above example we only need to apply one projection which represents both the flipping a reflection and the scaling Especially in pipelines with many augmentation steps this avoids a lot of unnecessary computation In cases where the result of the projection is cropped we can save additional computing by only evaluating the parts that we want to keep Cropping By default the bounds of a projected item will be chosen so they still encase all the data So after applying a  Scale((2 2  to an  Image  its bounds will also be scaled by 2 Sometimes however we want to crop a part of the projected output for example so a number of images can later be batched into a single array While the crop usually has a fixed size the region to crop still needs to be chosen For validation data which should be transformed deterministically a center crop is usually used For training data on the other hand a random region is selected to add additional augmentation Read on to find out  how projective transformations are implemented  or jump straight to the  usage section "},{"doctype":"documentation","id":"references/DataAugmentation.MapElem","title":"MapElem","text":"Applies  f  to every element in an  AbstractArrayItem "},{"doctype":"documentation","id":"references/DataAugmentation.allequal","title":"allequal","text":""}]