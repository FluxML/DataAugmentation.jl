[{"body":"Examples","id":"docstrings/DataAugmentation.makebounds.html#examples"},{"body":"private   project!   —   function Project  item  using projection  P  and crop to  indices  if given . Store result in  bufitem .  Inplace version of  project . Default implementation falls back to  project .","id":"docstrings/DataAugmentation.project!.html"},{"body":"public   BoundingBox   —   parametric type Item wrapper around  Keypoints .","id":"docstrings/DataAugmentation.BoundingBox.html"},{"body":"public   Normalize   —   parametric type Normalizes the last dimension of an  AbstractArrayItem{N} . Supports  apply! .","id":"docstrings/DataAugmentation.Normalize.html"},{"body":"Rotate Rotate counter - clockwise by an angle .","id":"docs/literate/projective/gallery.html#rotate"},{"body":"public   PinOrigin   —   struct Projective transformation that translates the data so that the upper left bounding corner is at the origin  (0, 0)  (or the multidimensional equivalent) . Projective transformations on images return  OffsetArray s, but not on keypoints .  Hardware like GPUs do not support OffsetArrays, so they will be unwrapped and no longer match up with the keypoints . Pinning the data to the origin makes sure that the resulting OffsetArray  has the same indices as a regular array, starting at one .","id":"docstrings/DataAugmentation.PinOrigin.html"},{"body":"Examples","id":"docstrings/DataAugmentation.MaskMulti.html#examples"},{"body":"public   Image   —   parametric type Item representing an N - dimensional image with element type T .","id":"docstrings/DataAugmentation.Image.html"},{"body":"private   project   —   function Project  item  using projection  P  and crop to  indices  if given .","id":"docstrings/DataAugmentation.project.html"},{"body":"Name Module Visibility Category  AbstractArrayItem   DataAugmentation   private   parametric type   AbstractItem   DataAugmentation   private   type   ArrayItem   DataAugmentation   public   parametric type   BoundingBox   DataAugmentation   public   parametric type   ComposedProjectiveTransform   DataAugmentation   private   parametric type   Identity   DataAugmentation   public   struct   Image   DataAugmentation   public   parametric type   ImageToTensor   DataAugmentation   public   parametric type   Item   DataAugmentation   public   type   ItemWrapper   DataAugmentation   private   parametric type   Keypoints   DataAugmentation   public   parametric type   MapElem   DataAugmentation   public   struct   MaskBinary   DataAugmentation   public   parametric type   MaskMulti   DataAugmentation   public   parametric type   Normalize   DataAugmentation   public   parametric type   PinOrigin   DataAugmentation   public   struct   Polygon   DataAugmentation   public   parametric type   ProjectiveTransform   DataAugmentation   private   type   Reflect   DataAugmentation   public   parametric type   Rotate   DataAugmentation   public   parametric type   ScaleFixed   DataAugmentation   public   parametric type   ScaleKeepAspect   DataAugmentation   public   parametric type   Sequence   DataAugmentation   public   parametric type   ToEltype   DataAugmentation   public   parametric type   Transform   DataAugmentation   public   type   apply!   DataAugmentation   public   function   apply   DataAugmentation   public   function   boundssize   DataAugmentation   private   function   compose   DataAugmentation   private   function   cropindices   DataAugmentation   private   function   getbounds   DataAugmentation   private   function   getprojection   DataAugmentation   private   function   getrandstate   DataAugmentation   private   function   itemdata   DataAugmentation   public   function   makebounds   DataAugmentation   private   function   makebuffer   DataAugmentation   private   function   offsetcropindices   DataAugmentation   private   function   project!   DataAugmentation   private   function   project   DataAugmentation   private   function   showitem   DataAugmentation   public   function ","id":"docstrings.html#docstring-index"},{"body":"Gallery Let ’ s visualize what these projective transformations look like . You can apply them to  Image s and the keypoint - based items  Keypoints ,  Polygon , and  BoundingBox . Let ’ s take this picture of a light house: To apply a transformation  tfm  to it, wrap it in Image , apply the transformation and unwrap it using  itemdata : Now let ’ s say we want to train a light house detector and have a bounding box for the light house .  We can use the  BoundingBox  item to represent it . It takes the two corners of the bounding rectangle as the first argument .  As the second argument we have to pass the size of the corresponding image . showitem  visualizes the two items: If we apply transformations like translation and cropping to the image, then the same transformations have to be applied to the bounding box .  Otherwise, the bounding box will no longer match up with the light house . Another problem can occur with stochastic transformations like  RandomResizeCrop . If we apply it separately to the image and the bounding box, they will be cropped from slightly different locations: Instead, pass a tuple of the items to a single  apply  call so the same random state will be used for both image and bounding box: We ’ ll use a 2 - dimensional  Image  and  BoundingBox  here, but you can apply most projective transformations to any spatial item (including  Keypoints , MaskBinary  and  MaskMulti ) in 3 dimensions . Of course, you have to create a 3 - dimensional transformation, i . e . CenterCrop((128, 128, 128))  instead of  CenterCrop((128, 128)) .","id":"docs/literate/projective/gallery.html#gallery"},{"body":"Buffering As mentioned in the section on  transformations , you can implement  apply!  as an inplace version of  apply  to support buffered transformations .  Usually, the result of a regular  apply  can be used as a buffer .  You may write However, for some transformations, a different buffer is needed .   Sequence , for example, needs to reuse all intermediate results .  That is why the buffer creation can be customized: makebuffer (tfm, item)  creates a buffer  buf  that can be used in an  apply!  call:  apply!(buf, tfm, item) . Managing the buffers manually quickly becomes tedious .  For convenience, this library implements  Buffered , a transformation wrapper that will use a buffer internally .   btfm = Buffered(tfm)  will create a buffer the first time it is  apply ed and then use it by internally calling  apply! . Since  Buffered  only stores one buffer, you may run into problems when using it in a multi - threading context where different threads invalidate the buffer before it can be used .  In that case, you can use  BufferedThreadsafe , a version of  Buffered  that keeps a separate buffer for every thread .","id":"docs/literate/buffering.html#buffering"},{"body":"public   Sequence   —   parametric type Transform  that applies multiple  transformations after each other . You should not use this explicitly .  Instead use  compose .","id":"docstrings/DataAugmentation.Sequence.html"},{"body":"Requirements The above example is simple, but there are more requirements of data augmentation pipelines that this library adresses .  They serve as a motivation to the interface I ’ ve arrived at for defining transformations .","id":"docs/literate/intro.html#requirements"},{"body":"public   ToEltype   —   parametric type Converts any  AbstractArrayItem  to an  AbstractArrayItem{N, T} . Supports  apply! .","id":"docstrings/DataAugmentation.ToEltype.html"},{"body":"private   makebounds   —   function Helper for creating spatial bounds .","id":"docstrings/DataAugmentation.makebounds.html"},{"body":"private   compose   —   function Compose tranformations .  Use  |>  as an alias . Defaults to creating a  Sequence  of transformations, but smarter behavior can be implemented . For example,  MapElem(f) |> MapElem(g) == MapElem(g ∘ f) .","id":"docstrings/DataAugmentation.compose.html"},{"body":"Examples Preprocessing a 3D image with 3 color channels .","id":"docstrings/DataAugmentation.Normalize.html#examples"},{"body":"Examples","id":"docstrings/DataAugmentation.ToEltype.html#examples"},{"body":"RandomResizeCrop (sz) Resizes the sides so that one of them is no longer than  sz  and crops a region of size  sz   from a random location .","id":"docs/literate/projective/gallery.html#randomresizecropsz"},{"body":"private   boundssize   —   function (100, 100) |> makebounds |> boundssize == (100, 100)","id":"docstrings/DataAugmentation.boundssize.html"},{"body":"Examples","id":"docstrings/DataAugmentation.BoundingBox.html#examples"},{"body":"Example The implementation of the  MapElem  transformation illustrates this interface well .  It transforms any item with array data by mapping a function over the array ’ s elements, just like  Base.map . The  apply  implementation dispatches on  AbstractArrayItem , an abstract item type for items that wrap arrays .  Note that the  randstate  keyword argument needs to be given even for implementations of deterministic transformations .  We also make use of the  setdata  helper to update the item data . The buffered version applies the function inplace using  Base.map! : Finally, a  MapElem  can also be composed nicely with other  MapElem s .  Instead of applying them sequentially, the functions are fused and applied once .","id":"docs/literate/tfminterface.html#example"},{"body":"public   ImageToTensor   —   parametric type Expands an  Image{N, T}  of size  sz  to an  ArrayItem{N+1}  with size  (sz..., ch)  where  ch  is the number of color channels of  T . Supports  apply! .","id":"docstrings/DataAugmentation.ImageToTensor.html"},{"body":"private   makebuffer   —   function Create a buffer  buf  that can be used in a call to  apply!(buf, tfm, item) . Default to  buffer = apply(tfm, item) . You only need to implement this if the default  apply(tfm, item)  isn ’ t enough .  See  apply(tfm::Sequence, item)  for an example of this .","id":"docstrings/DataAugmentation.makebuffer.html"},{"body":"Crops To get a cropped result, simply  compose  any  ProjectiveTransform  with CenterCrop  to crop a fixed - size region from the center; or RandomCrop  to crop a fixed - size region from a random position","id":"docs/literate/projective/usage.html#crops"},{"body":"Examples","id":"docstrings/DataAugmentation.MaskBinary.html#examples"},{"body":"Item interface As described previously, items are simply containers for data: an  Image  represents an image, and  Keypoints  some keypoints .","id":"docs/literate/iteminterface.html#item-interface"},{"body":"DataAugmentation . jl This library provides data transformations for machine and deep learning .  At the moment, it focuses on spatial data (think images, keypoint data and masks), but that is owed only to my current work .  The extensible abstractions should fit other domains as well . For the most part, the transformations themselves are not very complex .  The challenge this library tackles is to reconcile an easy - to - use, composable interface with performant execution . The key abstractions are  Transform s, the transformation to apply, and  Item s which contain the data to be transformed .   apply (tfm, item) , as the name gives away, applies a transformation to an item .   For example, given an  Image  item, we can resize it with the  CenterResizeCrop  transformation .","id":"docs/literate/intro.html#dataaugmentationjl"},{"body":"Creating items To create a new item, you can simply subtype  Item : The only function that is expected to be implemented is  itemdata , which simply returns the wrapped data .  If, as above, you simply call the field holding the data  data , you do not need to implement it .  The same goes for the  setdata  helper . For some items, it also makes sense to implement the following: showitem (item::I)  creates a visual representation of an item .  Should return something that can be shown as an image .","id":"docs/literate/iteminterface.html#creating-items"},{"body":"FlipX ,  FlipY ,  Reflect Flip the data on the horizontally and vertically, respectively .  More generally, reflect around an angle from the x - axis .","id":"docs/literate/projective/gallery.html#flipx-flipy-reflect"},{"body":"Gallery","id":"docs/literate/projective/gallery.html#gallery-1"},{"body":"Buffering Since data augmentation pipelines often run on large amounts of data, performance can often be improved by using prealloacted output buffers for the transformations .  This results in fewer memory allocations and less garbage collection which both take time . Let ’ s next see how these requirements are reflected in the  item  and  transformation  interfaces .","id":"docs/literate/intro.html#buffering"},{"body":"public   ScaleKeepAspect   —   parametric type Projective transformation that scales the shortest side of  item to  minlengths , keeping the original aspect ratio .","id":"docstrings/DataAugmentation.ScaleKeepAspect.html"},{"body":"private   AbstractArrayItem   —   parametric type Abstract type for all  [ Item ] s that wrap an  N - dimensional array with element type  T .","id":"docstrings/DataAugmentation.AbstractArrayItem.html"},{"body":"private   getprojection   —   function Create a projection for an item with spatial bounds  bounds . The projection should be a  CoordinateTransformations.Transformation . See  CoordinateTransformations . jl","id":"docstrings/DataAugmentation.getprojection.html"},{"body":"private   getbounds   —   function Return the spatial bounds of  item .  For a 2D - image ( Image{2} ) the bounds are the 4 corners of the bounding rectangle .  In general, for an N - dimensional item, the bounds are a vector of the N^2 corners of the N - dimensional hypercube bounding the data .  In practive, use makebounds  to construct the bounds from a tuple of side lengths .","id":"docstrings/DataAugmentation.getbounds.html"},{"body":"Examples","id":"docstrings/DataAugmentation.Rotate.html#examples"},{"body":"public   MaskBinary   —   parametric type An  N - dimensional binary mask .","id":"docstrings/DataAugmentation.MaskBinary.html"},{"body":"private   cropindices   —   function","id":"docstrings/DataAugmentation.cropindices.html"},{"body":"Examples If  T  is not a color, the image will be interpreted as grayscale:","id":"docstrings/DataAugmentation.Image.html#examples"},{"body":"public   Rotate   —   parametric type Rotate 2D spatial data counter - clockwise by angle γ around the center .  If you pass in a vector of angles, one will be randomly selected .","id":"docstrings/DataAugmentation.Rotate.html"},{"body":"public   MapElem   —   struct Applies  f  to every element in an  [ AbstractArrayItem ] .","id":"docstrings/DataAugmentation.MapElem.html"},{"body":"Crop (sz[, from]) Crops a region of size  sz  from the image,  without resizing  the image first .","id":"docs/literate/projective/gallery.html#cropsz-from"},{"body":"Why do I need to wrap my data in an item? For one, the item  struct s may contain metadata that is useful for some transformations .  More importantly, though, by wrapping data in an item type, the  meaning  of the data is separated from the  representation , that is, the concrete type . An  Array{Integer, 2}  could represent an image, but also a multi - class segmentation mask .  Is  Array{Float32, 3}  a 3 - dimensional image or a 2 - dimensional image with the color channels expanded? Separating the representation from the data ’ s meaning resolves those ambiguities .","id":"docs/literate/iteminterface.html#why-do-i-need-to-wrap-my-data-in-an-item"},{"body":"public   Identity   —   struct The identity transformation .","id":"docstrings/DataAugmentation.Identity.html"},{"body":"Spatial data Before introducing various projective transformations, we have a look at the data that can be projected .  There are three kinds of data currently supported: images, keypoints and segmentation masks .  Both 2D and 3D data is supported (and technically, higher dimensions, but I ’ ve yet to find a dataset with 4 spatial dimensions) . Image {N, T}  represents an  N - dimensional image .   T  refers to the element type of the array that  Image  wraps, usually a color .  When projecting images, proper interpolation methods are used to reduce artifacts like aliasing .  See  image.jl MaskBinary {N}  and  MaskMulti {N, T}  likewise represents  N - dimensional segmentation masks .  Unlike images, nearest - neighbor interpolation is used for projecting masks .  See  mask.jl Lastly,  Keypoints {N}  represent keypoint data .  The data should be an array of  SVector{N} .  Since there are many interpretations of keypoint data, there are also wrapper items for convenience:  BoundingBox  and  Polygon . See  keypoints.jl","id":"docs/literate/projective/data.html#spatial-data"},{"body":"private   ItemWrapper   —   parametric type","id":"docstrings/DataAugmentation.ItemWrapper.html"},{"body":"private   getrandstate   —   function Generates random state for stochastic transformations . Calling  apply(tfm, item)  is equivalent to apply(tfm, item; randstate = getrandstate(tfm)) .  It defaults to  nothing , so you it only needs to be implemented for stochastic  Transform s .","id":"docstrings/DataAugmentation.getrandstate.html"},{"body":"public   Item   —   type Abstract supertype of concrete items . Subtype if you want to create a new item .  If you want to wrap an existing item, see  ItemWrapper .","id":"docstrings/DataAugmentation.Item.html"},{"body":"private   ComposedProjectiveTransform   —   parametric type Wrap multiple projective  tfms  and apply them efficiently . The projections are fused into a single projection and only points inside the final crop are evaluated .","id":"docstrings/DataAugmentation.ComposedProjectiveTransform.html"},{"body":"An example pipeline We can break down most augmentation used in practive into a single (possibly stochastic) projection and a crop . As an example, consider an image augmentation pipeline: A random horizontal flip, followed by a random resized crop .  The latter resizes and crops (irregularly sized) images to a common size without distorting the aspect ratio . Let ’ s pull apart the steps involved . Half of the time, flip the image horizontally . Scale the image down without distortion so that the shorter side length is 128 .  With an input of size  (512, 256)  this result in scaling both dimensions by  1/2 , resulting in an image with side lengths  (256, 128) . Crop a random  (128, 128)  portion from that image .  There is only  “ wiggle room ”  on the y - axis (which, by convention, is the first) . All of these steps can be efficiently computed in one step with two tricks: Some projections like reflection, translation, scaling and rotation can be composed into a single projection matrix .  This means in the above example we only need to apply one projection which represents both the flipping (a reflection) and the scaling .  Especially in pipelines with many augmentation steps this avoids a lot of unnecessary computation . In cases, where the result of the projection is cropped, we can save additional computing by only evaluating the parts that we want to keep .","id":"docs/literate/projective/intro.html#an-example-pipeline"},{"body":"CenterResizeCrop Resizes the sides so that one of them is no longer than  sz  and crops a region of size  sz   from the center .","id":"docs/literate/projective/gallery.html#centerresizecrop"},{"body":"Examples","id":"docstrings/DataAugmentation.Keypoints.html#examples"},{"body":"Composition Most data augmentation pipelines are made up of multiple steps: augmenting an image can mean resizing, randomly rotating, cropping and then normalizing the values .  So applying transformations one after another – sequencing – is one way to compose transformations .  But some operations, like affine transformations, can also be  fused , resulting in a single transformation that is more performant and produces more accurate results .","id":"docs/literate/intro.html#composition"},{"body":"public   itemdata   —   function Access the data wrapped in  item  or a tuple of items .","id":"docstrings/DataAugmentation.itemdata.html"},{"body":"public   MaskMulti   —   parametric type An  N - dimensional multilabel mask with labels  classes .","id":"docstrings/DataAugmentation.MaskMulti.html"},{"body":"Projective transformations DataAugmentation . jl has great support for transforming spatial data like images and keypoints .  Most of these transformations are projective transformations .  For our purposes, a projection means a mapping between two coordinate spaces .  In computer vision, these are frequently used for preprocessing and augmenting image data: images are randomly scaled, maybe flipped horizontally and finally cropped to the same size . This library generalizes projective transformations for different kinds of image and keypoint data in an N - dimensional Euclidean space .  It also uses composition for performance improvements like fusing affine transformations . Unlike mathematical objects, the spatial data we want to transform has  spatial bounds .  For an image, these bounds are akin to the array size .  But keypoint data aligned with an image has the same bounds even if they are not explicitly encoded in the representation of the data . These spatial bounds can be used to dynamically create useful transformations .  For example, a rotation around the center or a horizontal flip of keypoint annotations can be calculated from the bounds . Often, we also want to  crop  an area from the projected results .  By evaluating only the parts of a projection that fall inside the cropped area, a lot of unnecessary computation can be avoided .","id":"docs/literate/projective/intro.html#projective-transformations"},{"body":"Usage Using projective transformations is as simple as any other transformations .  Simply  compose  them: The composition will automatically create a single projective transformation and evaluate only the cropped area .","id":"docs/literate/projective/usage.html#usage"},{"body":"public   Transform   —   type Abstract supertype for all transformations .","id":"docstrings/DataAugmentation.Transform.html"},{"body":"public   Keypoints   —   parametric type N - dimensional keypoints represented as  SVector{N, T} . Spatial bounds are given by the polygon  bounds::Vector{SVector{N, T}} or  sz::NTuple{N, Int} .","id":"docstrings/DataAugmentation.Keypoints.html"},{"body":"Examples","id":"docstrings/DataAugmentation.Reflect.html#examples"},{"body":"public   showitem   —   function Visualize  item .  Should return an image .","id":"docstrings/DataAugmentation.showitem.html"},{"body":"private   ProjectiveTransform   —   type Abstract supertype for projective transformations .  See Projective transformations .","id":"docstrings/DataAugmentation.ProjectiveTransform.html"},{"body":"Examples","id":"docstrings/DataAugmentation.ImageToTensor.html#examples"},{"body":"public   ArrayItem   —   parametric type An item that contains an array .","id":"docstrings/DataAugmentation.ArrayItem.html"},{"body":"Affine transformations Affine transformations are a subgroup of projective transformations that can be composed very efficiently: composing two affine transformations results in another affine transformation .  Affine transformations can represent translation, scaling, reflection and rotation .  Available  Transform s are: ScaleRatio ,  ScaleKeepAspect Rotate FlipX ,  FlipY ,  Reflect","id":"docs/literate/projective/usage.html#affine-transformations"},{"body":"Stochasticity A transformation is stochastic (as opposed to deterministic) if it produces different outputs based on some random state . This randomness can become a problem when applying an transformation to an aligned pair of input and target .  If we have an image and a corresponding segmentation mask, using different scaling factors results in misalignment of the two; the segmentation no longer matches up with the image pixels . To handle this, the random state is explicitly passed to the transformations, rendering them deterministic .  A generator for the random state can be defined with  getrandstate (tfm)  and passed to  apply  with the  randstate  keyword argument .","id":"docs/literate/intro.html#stochasticity"},{"body":"public   apply   —   function Apply  tfm  to an  item  or a tuple  items .","id":"docstrings/DataAugmentation.apply.html"},{"body":"Transformation interface base.jl The transformation interface is the centrepiece of this library .  Beside straightforward transform application it also enables stochasticity, composition and buffering . A transformation is a type that subtypes  Transform .  The only  required  function to implement for your transformation type  T  is apply (tfm::T, item::I; randstate) Applies the transformation  tfm  to item  item .  Implemented methods can of course dispatch on the type of  item .   randstate  encapsulates the random state needed for stochastic transformations .  The  apply  method implementation itself should be deterministic . You may dispatch on a specific item type  I  or use the abstract  Item  if one implementation works for all item types . You may additionally also implement: getrandstate (tfm)  for  stochastic  transformations Generates random state to be used inside  apply .  Calling  apply(tfm, item)  is equivalent to apply(tfm, item; randstate = getrandstate(tfm)) .  It defaults to  nothing , so we need not implement it for deterministic transformations . apply! (bufitem, tfm::T, item; randstate)  to support  buffering Buffered version of  apply  that mutates  bufitem .  If not implemented, falls back to regular  apply . compose (tfm1, tfm2)  for custom  composition  with other transformations Composes transformations .  By default, returns a  Sequence  transformation that applies the transformations one after the other .","id":"docs/literate/tfminterface.html#transformation-interface"},{"body":"private   AbstractItem   —   type Abstract supertype for all items .  To implement items, subtype either  Item  to create a new item or  ItemWrapper to wrap an existing item .","id":"docstrings/DataAugmentation.AbstractItem.html"},{"body":"public   apply!   —   function Applies  tfm  to  item , mutating the preallocated  buffer . buffer  can be obtained with  buffer = makebuffer(tfm, item) Default to  apply(tfm, item)  (non - mutating version) .","id":"docstrings/DataAugmentation.apply!.html"},{"body":"Cropping By default, the bounds of a projected item will be chosen so they still encase all the data .  So after applying a  Scale((2, 2))  to an  Image , its bounds will also be scaled by 2 .  Sometimes, however, we want to crop a part of the projected output, for example so a number of images can later be batched into a single array .  While the crop usually has a fixed size, the region to crop still needs to be chosen .  For validation data (which should be transformed deterministically), a center crop is usually used .  For training data, on the other hand, a random region is selected to add additional augmentation . Read on to find out  how projective transformations are implemented  or jump straight to the  usage section .","id":"docs/literate/projective/intro.html#cropping"},{"body":"Examples","id":"docstrings/DataAugmentation.Polygon.html#examples"},{"body":"public   Polygon   —   parametric type Item wrapper around  Keypoints .","id":"docstrings/DataAugmentation.Polygon.html"},{"body":"private   offsetcropindices   —   function Calculate indices for a crop of size  sz  out of  indices . Input and output indices are represented as tuples of ranges . For every dimension i where  sz[i] < length(indices[i]) , offsets the crop by  offsets[i]  times the difference between the two .","id":"docstrings/DataAugmentation.offsetcropindices.html"},{"body":"Preprocessing This library also implements some general transformations useful for getting data ready to be put into a model . ToEltype (T)  converts the element type of any  AbstractArrayItem  to  T . ImageToTensor  converts an image to an  ArrayItem  with another dimension for the color channels Normalize  normalizes image tensors","id":"docs/literate/preprocessing.html#preprocessing"},{"body":"public   ScaleFixed   —   parametric type Projective transformation that scales sides to  sizes , disregarding aspect ratio . See also  ScaleKeepAspect .","id":"docstrings/DataAugmentation.ScaleFixed.html"},{"body":"public   Reflect   —   parametric type Reflect 2D spatial data by angle γ around the center . If you pass in a vector of angles, one will be randomly selected .","id":"docstrings/DataAugmentation.Reflect.html"},{"body":"Projective transformations interface The abstract type  ProjectiveTransform  represents a projective transformation . A  ProjectiveTransform  needs to implement  getprojection (tfm, bounds; randstate)  that should return a  Transformation  from  CoordinateTransformations . jl . To add support for projective transformations to an item  I , you need to implement getbounds(item::I)  returns the spatial bounds of the item; and project(P, item::I, indices)  applies the projective transformation  P  and crops to  indices To support  apply! - ing projective transformations,  project!(bufitem, P, item)  can also be implemented .","id":"docs/literate/projective/interface.html#projective-transformations-interface"}]